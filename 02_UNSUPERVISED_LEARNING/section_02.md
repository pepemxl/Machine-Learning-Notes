# Clustering  in Big Data

Clustering is a popular unsupervised method and an essential tool for Big Data Analysis. 

Clustering can be used either as a pre-processing step to reduce data dimensionality before running the learning algorithm, or as a statistical tool to discover useful patterns within a dataset. 

Clustering methods are based on iterative optimization. 

Although these methods are effective in extracting useful pattern from datasets, they consume massive computing resources and come with high computational costs due to the high dimensionality associated with contemporary data applications.


## Challenges of clustering big data

The challenges of clustering big data are characterized into three main components:

1. Volume: as the scale of the data generated by modern technologies is rising exponentially, clustering methods become computationally expensive and do not scale up to very large datasets.
2. Velocity: this refers to the rate of speed in which data is incoming to the system. Dealing with high velocity data requires the development of more dynamic clustering methods to derive useful information in real time.
3. Variety: Current data are heterogeneous and mostly unstructured, which make the issue to manage, merge and govern data extremely challenging.


- K-means Based Clustering
    - Machine Learning
    - Fuzzy
    - Statistics
    - Scalable
- Hierarchical Clustering
    - Data Mining
    - Machine Learning
    - Scalable 
- Density Based Clustering
    - Graph
    - Machine Learning
    - Data Mining
    - Scalablew